{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "\n",
    "def get_output(instance_tokens):\n",
    "    debug = True\n",
    "    if debug:\n",
    "        print(0, instance_tokens)\n",
    "    # Define the URL of the form endpoint\n",
    "    url = 'http://127.0.0.1:5000'\n",
    "\n",
    "    # Change the textarea (of name user_input) value to a custom text\n",
    "    text = \" \".join(instance_tokens)\n",
    "    data = {\n",
    "        'user_input': text\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    # get the p with the class \"text-result\"\n",
    "    if len(response.text) == 0:\n",
    "        return \"Attention! No output was found.\"\n",
    "    try:\n",
    "        out = response.text.split('<p class=\"text-result\">')[1].split('</p>')[0]\n",
    "    except:\n",
    "        print(response.text)\n",
    "    # create list\n",
    "    out = out.split('</span></span>')[:-1]\n",
    "    d = {'tokens': [],\n",
    "            'ner_tags': [],\n",
    "            'confidence': []}\n",
    "    for o in out:\n",
    "        # find where highlight label- is and add the number after it to the dictionary\n",
    "        d['ner_tags'].append(int(o.split('highlight label-')[1][0]))\n",
    "        # find the text of the label\n",
    "        text = o.split('\">')[1].split('<span')[0]\n",
    "        d['tokens'].append(text)\n",
    "        if len(text) == 1:\n",
    "            confidence = 100.0\n",
    "        else:\n",
    "            confidence = o[::-1][1:6][::-1]\n",
    "            if confidence[0] =='>':\n",
    "                confidence = confidence[1:]\n",
    "            confidence = float(confidence)\n",
    "        d['confidence'].append(confidence)\n",
    "\n",
    "    if debug:\n",
    "        print(1, d['tokens'])\n",
    "\n",
    "    # map d, 0->'B-O', 1->'B-AC', 2->'B-LF', 3->'I-LF'  \n",
    "    d['ner_tags'] = ['B-O' if x == 0 else 'B-AC' if x == 1 else 'B-LF' if x == 2 else 'I-LF' if x == 3 else 'ERROR' for x in d['ner_tags']]\n",
    "\n",
    "    # go through the tokens and if there is a space in the token, divide it into multiple tokens and add the same label and confidence\n",
    "\n",
    "    out = {'tokens': [], 'ner_tags': [], 'confidence': []}\n",
    "    for i in range(len(d['tokens'])):\n",
    "        if ' ' in d['tokens'][i]:\n",
    "            # split the token into multiple tokens\n",
    "            tokens = d['tokens'][i].split(' ')\n",
    "            for j in range(len(tokens)):\n",
    "                out['tokens'].append(tokens[j])\n",
    "                out['ner_tags'].append(d['ner_tags'][i])\n",
    "                out['confidence'].append(d['confidence'][i])\n",
    "        else:\n",
    "            out['tokens'].append(d['tokens'][i])\n",
    "            out['ner_tags'].append(d['ner_tags'][i])\n",
    "            out['confidence'].append(d['confidence'][i])\n",
    "\n",
    "    if debug:\n",
    "        print(2, out['tokens'])\n",
    "\n",
    "    tokens_to_merge = find_tokens_to_merge(out['tokens'], instance_tokens)         \n",
    "\n",
    "    new_out = deepcopy(out)\n",
    "\n",
    "    # Merge the tokens\n",
    "    to_remove = []\n",
    "    for merge_list in tokens_to_merge:\n",
    "        # Merge the tokens\n",
    "        merged_token = ''.join([out['tokens'][i] for i in merge_list])\n",
    "        out['tokens'][merge_list[0]] = merged_token\n",
    "        to_remove.append(merge_list[1:])\n",
    "        # Merge the NER tags\n",
    "        out['ner_tags'][merge_list[0]] = out['ner_tags'][merge_list[0]]\n",
    "        # Merge the confidence\n",
    "        out['confidence'][merge_list[0]] = out['confidence'][merge_list[0]]\n",
    "\n",
    "    # flatten to_remove\n",
    "    to_remove = [item for sublist in to_remove for item in sublist]\n",
    "\n",
    "    # remove the tokens that were merged\n",
    "    new_out['tokens'] = [i for j, i in enumerate(out['tokens']) if j not in to_remove]\n",
    "    new_out['ner_tags'] = [i for j, i in enumerate(out['ner_tags']) if j not in to_remove]\n",
    "    new_out['confidence'] = [i for j, i in enumerate(out['confidence']) if j not in to_remove]\n",
    "    out = new_out\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def find_tokens_to_merge(mine, theirs):\n",
    "    # Initialize indices and result list\n",
    "    mine_index = 0\n",
    "    theirs_index = 0\n",
    "    merged_indices = []\n",
    "\n",
    "    # Traverse through 'theirs' list to find corresponding tokens in 'mine'\n",
    "    while theirs_index < len(theirs):\n",
    "        # Start merging tokens from 'mine' to match the current 'theirs' token\n",
    "        temp_token = ''\n",
    "        merge_list = []\n",
    "        while mine_index < len(mine) and temp_token != theirs[theirs_index]:\n",
    "            temp_token += mine[mine_index]\n",
    "            merge_list.append(mine_index)\n",
    "            mine_index += 1\n",
    "\n",
    "        # Check if the tokens merged correctly\n",
    "        if temp_token == theirs[theirs_index]:\n",
    "            if len(merge_list) > 1:\n",
    "                merged_indices.append(merge_list)\n",
    "            theirs_index += 1\n",
    "        else:\n",
    "            print(\"Mine:\", mine)\n",
    "            print(\"Theirs:\", theirs)\n",
    "            raise ValueError(f\"Cannot merge tokens to match '{theirs[theirs_index]}' from '{mine}'\")\n",
    "\n",
    "    return merged_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 16, 17], [58, 59], [85, 86, 87]]\n",
      "['1', ',', '4']\n",
      "['V', '.']\n",
      "['22', ',', '24']\n",
      "1,4\n",
      "V.\n",
      "22,24\n",
      "['Fractions', 'from', 'FPLC', 'purification', 'were', 'treated', 'with', 'Laemmli', 'buffer', '[', '82', ']', 'with', '10', 'mM', '1', ',', '4', '-', 'dithiothreitol', '(', 'DTT', ')', 'and', 'heated', 'for', '5', 'm', 'at', '85', '°', 'C', 'then', 'analyzed', 'on', 'a', '4', '%', 'to', '15', '%', 'discontinuous', 'SDS', 'gel', 'with', 'a', '6', '%', 'stacking', 'gel', 'run', 'at', 'ambient', 'temperature', 'at', 'a', 'constant', '100', 'V', '.', 'Two', 'epithelial', 'cytokines', 'other', 'than', 'IL33', ',', 'IL25', ',', 'and', 'thymic', 'stromal', 'lymphopoietin', '(', 'TSLP', ')', 'are', 'known', 'to', 'activate', 'ILC2', 'in', 'the', 'lung', '[', '22', ',', '24', ']', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mine = ['Fractions', 'from', 'FPLC', 'purification', 'were', 'treated', 'with', 'Laemmli', 'buffer', '[', '82', ']', 'with', '10', 'mM', '1', ',', '4', '-', 'dithiothreitol', '(', 'DTT', ')', 'and', 'heated', 'for', '5', 'm', 'at', '85', '°', 'C', 'then', 'analyzed', 'on', 'a', '4', '%', 'to', '15', '%', 'discontinuous', 'SDS', 'gel', 'with', 'a', '6', '%', 'stacking', 'gel', 'run', 'at', 'ambient', 'temperature', 'at', 'a', 'constant', '100', 'V', '.', 'Two', 'epithelial', 'cytokines', 'other', 'than', 'IL33', ',', 'IL25', ',', 'and', 'thymic', 'stromal', 'lymphopoietin', '(', 'TSLP', ')', 'are', 'known', 'to', 'activate', 'ILC2', 'in', 'the', 'lung', '[', '22', ',', '24', ']', '.']\n",
    "theirs = ['Fractions', 'from', 'FPLC', 'purification', 'were', 'treated', 'with', 'Laemmli', 'buffer', '[', '82', ']', 'with', '10', 'mM', '1,4', '-', 'dithiothreitol', '(', 'DTT', ')', 'and', 'heated', 'for', '5', 'm', 'at', '85', '°', 'C', 'then', 'analyzed', 'on', 'a', '4', '%', 'to', '15', '%', 'discontinuous', 'SDS', 'gel', 'with', 'a', '6', '%', 'stacking', 'gel', 'run', 'at', 'ambient', 'temperature', 'at', 'a', 'constant', '100', 'V.', 'Two', 'epithelial', 'cytokines', 'other', 'than', 'IL33', ',', 'IL25', ',', 'and', 'thymic', 'stromal', 'lymphopoietin', '(', 'TSLP', ')', 'are', 'known', 'to', 'activate', 'ILC2', 'in', 'the', 'lung', '[', '22,24', ']', '.']\n",
    "\n",
    "tokens_to_merge = find_tokens_to_merge(mine, theirs)\n",
    "print(tokens_to_merge)\n",
    "\n",
    "for t in tokens_to_merge:\n",
    "    print([mine[i] for i in t])\n",
    "\n",
    "new_out = mine.copy()\n",
    "\n",
    "for merge_list in tokens_to_merge:\n",
    "    merged_token = ''.join([mine[i] for i in merge_list])\n",
    "    print(merged_token)\n",
    "    new_out = [merged_token if i == merge_list[0] else '' for i in range(len(mine))]\n",
    "print(mine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'want', 'to', 'see', 'you', 'ASAP', '(', 'as', 'soon', 'as', 'possible', ')', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tokens': ['I',\n",
       "  'want',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'ASAP',\n",
       "  '(',\n",
       "  'as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'possible',\n",
       "  ')',\n",
       "  '.'],\n",
       " 'ner_tags': ['B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-AC',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O',\n",
       "  'B-O'],\n",
       " 'confidence': [100.0,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  99.98,\n",
       "  100.0,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  99.99,\n",
       "  100.0,\n",
       "  100.0]}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output(['I', 'want', 'to', 'see', 'you', 'ASAP', '(', 'as', 'soon', 'as', 'possible', ')', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbreviations', ':', 'GEMS', ',', 'Global', 'Enteric', 'Multicenter', 'Study', ';', 'VIP', ',', 'ventilated', 'improved', 'pit', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Abbreviations',\n",
       "  ':',\n",
       "  'GEMS',\n",
       "  ',',\n",
       "  'Global',\n",
       "  'Enteric',\n",
       "  'Multicenter',\n",
       "  'Study',\n",
       "  ';',\n",
       "  'VIP',\n",
       "  ',',\n",
       "  'ventilated',\n",
       "  'improved',\n",
       "  'pit',\n",
       "  '.'],\n",
       " 'ner_tags': ['B-O',\n",
       "  'B-O',\n",
       "  'B-AC',\n",
       "  'B-O',\n",
       "  'B-LF',\n",
       "  'I-LF',\n",
       "  'I-LF',\n",
       "  'I-LF',\n",
       "  'B-O',\n",
       "  'B-AC',\n",
       "  'B-O',\n",
       "  'B-LF',\n",
       "  'I-LF',\n",
       "  'I-LF',\n",
       "  'B-O'],\n",
       " 'confidence': [99.99,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  99.99,\n",
       "  95.87,\n",
       "  100.0]}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output(test_dataset[0]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(test_dataset):\n",
    "    pred, true = [], []\n",
    "    for i, instance in enumerate(test_dataset):\n",
    "        print(i)\n",
    "        pred.append(get_output(instance['tokens'])['ner_tags'])\n",
    "        true.append(instance['ner_tags'])\n",
    "        if len(pred[-1]) != len(true[-1]):\n",
    "            print(i)\n",
    "            print(\"---- Error -----\")\n",
    "            print(instance['tokens'])\n",
    "            print(get_output(instance['tokens'])['tokens'])\n",
    "            print(len(pred[-1]))\n",
    "            print(len(true[-1]))\n",
    "            break\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Processed {i} sentences out of {len(test_dataset)}\")\n",
    "    # flatten the lists\n",
    "    pred = [item for sublist in pred for item in sublist]\n",
    "    true = [item for sublist in true for item in sublist]\n",
    "    return pred, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['Abbreviations', ':', 'GEMS', ',', 'Global', 'Enteric', 'Multicenter', 'Study', ';', 'VIP', ',', 'ventilated', 'improved', 'pit', '.']\n",
      "Processed 0 sentences out of 153\n",
      "1\n",
      "['Fractions', 'from', 'FPLC', 'purification', 'were', 'treated', 'with', 'Laemmli', 'buffer', '[', '82', ']', 'with', '10', 'mM', '1,4', '-', 'dithiothreitol', '(', 'DTT', ')', 'and', 'heated', 'for', '5', 'm', 'at', '85', '°', 'C', 'then', 'analyzed', 'on', 'a', '4', '%', 'to', '15', '%', 'discontinuous', 'SDS', 'gel', 'with', 'a', '6', '%', 'stacking', 'gel', 'run', 'at', 'ambient', 'temperature', 'at', 'a', 'constant', '100', 'V.', 'Two', 'epithelial', 'cytokines', 'other', 'than', 'IL33', ',', 'IL25', ',', 'and', 'thymic', 'stromal', 'lymphopoietin', '(', 'TSLP', ')', 'are', 'known', 'to', 'activate', 'ILC2', 'in', 'the', 'lung', '[', '22,24', ']', '.']\n",
      "2\n",
      "['We', 'developed', 'a', 'variant', 'of', 'gene', 'set', 'enrichment', 'analysis', '(', 'GSEA', ')', 'to', 'determine', 'whether', 'a', 'genetic', 'pathway', 'shows', 'evidence', 'for', 'age', 'regulation', '[', '23', ']', '.']\n",
      "3\n",
      "['Red', 'represents', 'samples', 'having', 'the', 'normalized', 'pY232', 'and/or', 'pY291', 'values', 'in', 'cancer', 'tissues', '≥', '1.1', 'folds', 'of', 'normal', 'tissues', '(', 'of', 'which', 'enhanced', 'pY232', 'and/or', 'pY291', 'level', 'may', 'be', 'indicative', 'of', 'dominant', 'survival', 'mode', 'of', 'Fas', 'signaling', ')', ';', 'blue', 'represents', 'samples', 'having', 'both', 'normalized', 'pY232', 'and', 'pY291', 'values', '<', '1.1', '(', 'of', 'which', 'pY232', 'and', 'pY291', 'levels', 'less', 'than', 'or', 'equal', 'to', 'normal', 'may', 'be', 'indicative', 'of', 'the', 'apoptosis', '-', 'ready', 'mode', 'of', 'Fas', 'signaling', ')', '.']\n",
      "Mine: ['Red', 'represents', 'samples', 'having', 'the', 'normalized', 'pY23', 'and', '/', 'or', 'pY29', 'values', 'in', 'cancer', 'tissues', '≥', '1', '.', '1', 'folds', 'of', 'normal', 'tissues', '(', 'of', 'which', 'enhanced', 'pY23', 'and', '/', 'or', 'pY29', 'level', 'may', 'be', 'indicative', 'of', 'dominant', 'survival', 'mode', 'of', 'Fas', 'signaling', ')', ';', 'blue', 'represents', 'samples', 'having', 'both', 'normalized', 'pY23', 'and', 'pY29', 'values', '<', '1', '.', '1', '(', 'of', 'which', 'pY23', 'and', 'pY29', 'levels', 'less', 'than', 'or', 'equal', 'to', 'normal', 'may', 'be', 'indicative', 'of', 'the', 'apoptosis', '-', 'ready', 'mode', 'of', 'Fas', 'signaling', ')', '.']\n",
      "Theirs: ['Red', 'represents', 'samples', 'having', 'the', 'normalized', 'pY232', 'and/or', 'pY291', 'values', 'in', 'cancer', 'tissues', '≥', '1.1', 'folds', 'of', 'normal', 'tissues', '(', 'of', 'which', 'enhanced', 'pY232', 'and/or', 'pY291', 'level', 'may', 'be', 'indicative', 'of', 'dominant', 'survival', 'mode', 'of', 'Fas', 'signaling', ')', ';', 'blue', 'represents', 'samples', 'having', 'both', 'normalized', 'pY232', 'and', 'pY291', 'values', '<', '1.1', '(', 'of', 'which', 'pY232', 'and', 'pY291', 'levels', 'less', 'than', 'or', 'equal', 'to', 'normal', 'may', 'be', 'indicative', 'of', 'the', 'apoptosis', '-', 'ready', 'mode', 'of', 'Fas', 'signaling', ')', '.']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot merge tokens to match 'pY232' from '['Red', 'represents', 'samples', 'having', 'the', 'normalized', 'pY23', 'and', '/', 'or', 'pY29', 'values', 'in', 'cancer', 'tissues', '≥', '1', '.', '1', 'folds', 'of', 'normal', 'tissues', '(', 'of', 'which', 'enhanced', 'pY23', 'and', '/', 'or', 'pY29', 'level', 'may', 'be', 'indicative', 'of', 'dominant', 'survival', 'mode', 'of', 'Fas', 'signaling', ')', ';', 'blue', 'represents', 'samples', 'having', 'both', 'normalized', 'pY23', 'and', 'pY29', 'values', '<', '1', '.', '1', '(', 'of', 'which', 'pY23', 'and', 'pY29', 'levels', 'less', 'than', 'or', 'equal', 'to', 'normal', 'may', 'be', 'indicative', 'of', 'the', 'apoptosis', '-', 'ready', 'mode', 'of', 'Fas', 'signaling', ')', '.']'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[302], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred, true \u001b[38;5;241m=\u001b[39m \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[301], line 5\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(test_dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, instance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dataset):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 5\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     true\u001b[38;5;241m.\u001b[39mappend(instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pred[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(true[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[295], line 69\u001b[0m, in \u001b[0;36mget_output\u001b[0;34m(instance_tokens)\u001b[0m\n\u001b[1;32m     66\u001b[0m         out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m     67\u001b[0m         out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[0;32m---> 69\u001b[0m tokens_to_merge \u001b[38;5;241m=\u001b[39m \u001b[43mfind_tokens_to_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_tokens\u001b[49m\u001b[43m)\u001b[49m         \n\u001b[1;32m     71\u001b[0m new_out \u001b[38;5;241m=\u001b[39m deepcopy(out)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Merge the tokens\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[295], line 120\u001b[0m, in \u001b[0;36mfind_tokens_to_merge\u001b[0;34m(mine, theirs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMine:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mine)\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheirs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, theirs)\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot merge tokens to match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheirs[theirs_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_indices\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot merge tokens to match 'pY232' from '['Red', 'represents', 'samples', 'having', 'the', 'normalized', 'pY23', 'and', '/', 'or', 'pY29', 'values', 'in', 'cancer', 'tissues', '≥', '1', '.', '1', 'folds', 'of', 'normal', 'tissues', '(', 'of', 'which', 'enhanced', 'pY23', 'and', '/', 'or', 'pY29', 'level', 'may', 'be', 'indicative', 'of', 'dominant', 'survival', 'mode', 'of', 'Fas', 'signaling', ')', ';', 'blue', 'represents', 'samples', 'having', 'both', 'normalized', 'pY23', 'and', 'pY29', 'values', '<', '1', '.', '1', '(', 'of', 'which', 'pY23', 'and', 'pY29', 'levels', 'less', 'than', 'or', 'equal', 'to', 'normal', 'may', 'be', 'indicative', 'of', 'the', 'apoptosis', '-', 'ready', 'mode', 'of', 'Fas', 'signaling', ')', '.']'"
     ]
    }
   ],
   "source": [
    "pred, true = compare(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 100)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred), len(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
